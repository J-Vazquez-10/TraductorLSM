import tensorflow as tf
from tensorflow.keras import models, layers
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
import os
import numpy as np
import json
import matplotlib.pyplot as plt

# ====================================================================
# --- 0. CONFIGURACIÃ“N INICIAL Y OPTIMIZACIÃ“N DE HARDWARE ---
# ====================================================================

os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"
NUM_CPU_CORES = os.cpu_count()

tf.config.threading.set_intra_op_parallelism_threads(NUM_CPU_CORES)
tf.config.threading.set_inter_op_parallelism_threads(NUM_CPU_CORES)
print(f"âœ… ConfiguraciÃ³n de CPU: {NUM_CPU_CORES} nÃºcleos disponibles.")

gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print("âœ… GPU detectada y VRAM optimizada.")
    except RuntimeError as e:
        print(f"âš ï¸ Error en configuraciÃ³n de GPU: {e}")
else:
    print("â„¹ï¸ No se detectÃ³ GPU. Usando CPU.")

# --- 1. PARÃMETROS CLAVE Y AJUSTE DE ESTABILIDAD ---
TRAIN_DIR = 'VOCALES/train'
TEST_DIR = 'VOCALES/test'

# ==================== SOLUCIÃ“N FASE 2: Ruta de Fondos ====================
BACKGROUNDS_DIR = 'backgrounds_pexels_400' # Â¡AsegÃºrate de que esta carpeta exista y tenga imÃ¡genes!
# =======================================================================

IMAGE_SIZE = (96, 96) 
BATCH_SIZE = 64 

VOWEL_CLASSES = ['A', 'E', 'I', 'O', 'U']
NUM_CLASSES = len(VOWEL_CLASSES) # Ahora es 5

EPOCHS = 50 

# ==================== SOLUCIÃ“N FASE 1: Tasa de Aprendizaje Segura ====================
LEARNING_RATE = 0.0001 
# ==================================================================================
ADAM_BETA_1 = 0.9
ADAM_BETA_2 = 0.999

# ==================== SOLUCIÃ“N FASE 2: ParÃ¡metros del Chroma Key (Fondo Verde) ====================
# Estos valores (en HSV) definen tu fondo verde. Â¡AJÃšSTALOS SI ES NECESARIO!
# H (Tono): 0.25 - 0.45 (rango para verdes)
# S (SaturaciÃ³n): > 0.4 (ignora verdes pÃ¡lidos)
# V (Valor/Brillo): > 0.2 (ignora verdes oscuros)
HSV_GREEN_MIN = tf.constant([0.25, 0.4, 0.2], dtype=tf.float32)
HSV_GREEN_MAX = tf.constant([0.45, 1.0, 1.0], dtype=tf.float32)
# ================================================================================================


# ====================================================================
# --- 2. NUEVO PIPELINE DE DATOS (Soluciones Fases 1 y 2) ---
# ====================================================================

def create_soft_augmentation_pipeline():
    """
    SOLUCIÃ“N FASE 1: Crea un pipeline de aumentaciÃ³n suave que no
    "destruye" la imagen.
    """
    return tf.keras.Sequential([
        layers.RandomRotation(0.1),       # RotaciÃ³n sutil (mÃ¡x 36 grados)
        layers.RandomZoom(0.1),         # Zoom sutil (mÃ¡x 10%)
        layers.RandomTranslation(0.05, 0.05), # TraslaciÃ³n sutil (~4-5 pÃ­xeles)
        layers.RandomFlip("horizontal"),
        layers.RandomContrast(0.1), 
        layers.RandomBrightness(0.1),
        layers.GaussianNoise(0.05),
    ], name="soft_augmentation_pipeline")


def chroma_key_blend(image, background):
    """
    SOLUCIÃ“N FASE 2: Reemplaza el fondo verde de 'image' con 'background'.
    Esto se ejecuta 100% en TensorFlow para alta eficiencia en la GPU.
    """
    # Convertir la imagen a HSV (es mÃ¡s fÃ¡cil aislar el verde)
    # Las imÃ¡genes de Keras estÃ¡n en [0, 255], HSV de TF espera [0, 1]
    image_hsv = tf.image.rgb_to_hsv(image / 255.0)
    
    # Dividir en canales H, S, V
    h, s, v = tf.split(image_hsv, 3, axis=-1)
    
    # Crear la mÃ¡scara: Comprobar quÃ© pÃ­xeles estÃ¡n DENTRO del rango verde
    mask_h = tf.logical_and(h >= HSV_GREEN_MIN[0], h <= HSV_GREEN_MAX[0])
    mask_s = tf.logical_and(s >= HSV_GREEN_MIN[1], s <= HSV_GREEN_MAX[1])
    mask_v = tf.logical_and(v >= HSV_GREEN_MIN[2], v <= HSV_GREEN_MAX[2])
    
    green_mask_bool = tf.logical_and(mask_h, tf.logical_and(mask_s, mask_v))
    
    # Invertir la mÃ¡scara: queremos la MANO (True), no el fondo (False)
    hand_mask_bool = tf.logical_not(green_mask_bool)
    
    # Convertir de booleano a float32 (0.0 o 1.0)
    hand_mask = tf.cast(hand_mask_bool, dtype=tf.float32)
    
    # Suavizar los bordes de la mÃ¡scara (truco rÃ¡pido de "blur")
    # Esto evita bordes duros y pixelados
    mask_small = tf.image.resize(hand_mask, (24, 24), method='bilinear')
    hand_mask_smooth = tf.image.resize(mask_small, IMAGE_SIZE, method='bilinear')

    # Normalizar el fondo tambiÃ©n a [0, 255] (si no lo estÃ¡ ya)
    # y asegurarse de que tenga el tamaÃ±o correcto
    background_resized = tf.image.resize(background, IMAGE_SIZE)
    
    # Combinar: (Mano * MÃ¡scara) + (Fondo * (1.0 - MÃ¡scara))
    # 'image' y 'background_resized' deben estar en el mismo rango [0, 255]
    blended_image = (image * hand_mask_smooth) + (background_resized * (1.0 - hand_mask_smooth))
    
    return blended_image


def load_backgrounds(directory, shuffle_buffer_size=1000):
    """Carga, redimensiona y repite infinitamente las imÃ¡genes de fondo."""
    print(f"Cargando fondos desde {directory}...")
    bg_ds = tf.keras.utils.image_dataset_from_directory(
        directory,
        labels=None, # No hay etiquetas
        image_size=IMAGE_SIZE, # Redimensionar fondos
        interpolation='bilinear',
        batch_size=None # Cargar imÃ¡genes individuales
    )
    
    # Crear un stream infinito y aleatorio de fondos
    bg_ds = bg_ds.shuffle(shuffle_buffer_size).repeat()
    return bg_ds


def load_and_optimize_data(directory, augment_pipeline, background_ds, augment=False, class_filter=None):
    """
    Pipeline de carga NUEVO Y COMPLETO.
    1. Carga imÃ¡genes (Color)
    2. Descomprime lotes
    3. Combina cada imagen con un fondo aleatorio
    4. Aplica el chroma key (Color)
    5. *** CONVIERTE A ESCALA DE GRISES ***
    6. Aplica aumentaciÃ³n suave (Grises)
    7. Re-empaqueta en lotes y optimiza
    """
    
    print(f"Cargando desde {directory}...")
    print(f"Filtrando solo clases: {class_filter}")
    
    dataset = tf.keras.utils.image_dataset_from_directory(
        directory,
        labels='inferred',
        label_mode='categorical',
        class_names=class_filter, 
        image_size=IMAGE_SIZE,
        interpolation='bilinear',
        batch_size=BATCH_SIZE, # Carga en lotes (mÃ¡s rÃ¡pido)
        shuffle=augment
    )
    
    class_names = dataset.class_names
    
    # Deshacer los lotes para procesar imagen por imagen
    dataset = dataset.unbatch()
    
    # Combinar el dataset de seÃ±as con el stream de fondos
    # Ahora cada elemento es: ((imagen, etiqueta), fondo)
    zipped_ds = tf.data.Dataset.zip((dataset, background_ds))
    
    # FunciÃ³n de mapeo principal
    @tf.function
    def process_image(data, background):
        image, label = data
        
        # SOLUCIÃ“N FASE 2: Reemplazar el fondo verde (sigue en RGB)
        blended_image_rgb = chroma_key_blend(image, background)
        
        # ===================================================================
        # --- Â¡CAMBIO AQUÃ! CONVERTIR A ESCALA DE GRISES ---
        # ===================================================================
        blended_image = tf.image.rgb_to_grayscale(blended_image_rgb)
        # ===================================================================

        # SOLUCIÃ“N FASE 1: Aplicar aumentaciÃ³n suave (ahora sobre grises)
        if augment:
            blended_image = augment_pipeline(blended_image, training=True)
            
        return blended_image, label
    
    dataset = zipped_ds.map(process_image, num_parallel_calls=tf.data.AUTOTUNE)
    
    # Re-empaquetar y optimizar
    dataset = dataset.batch(BATCH_SIZE)
    dataset = dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)
    
    return dataset, class_names

# --- Crear los pipelines ---
print("\nðŸ“ Cargando datos y pipelines...")

# 1. Cargar el stream de fondos
background_dataset = load_backgrounds(BACKGROUNDS_DIR)

# 2. Crear el pipeline de aumentaciÃ³n suave
soft_augment_pipeline = create_soft_augmentation_pipeline()

# 3. Cargar el dataset de entrenamiento
train_dataset, class_names = load_and_optimize_data(
    TRAIN_DIR,
    augment_pipeline=soft_augment_pipeline,
    background_ds=background_dataset,
    augment=True,
    class_filter=VOWEL_CLASSES
)

# 4. Cargar el dataset de validaciÃ³n
# (Nota: TambiÃ©n reemplazamos el fondo en validaciÃ³n para ser consistentes)
validation_dataset, _ = load_and_optimize_data(
    TEST_DIR,
    augment_pipeline=soft_augment_pipeline,
    background_ds=background_dataset,
    augment=False, # Sin aumentaciÃ³n en validaciÃ³n
    class_filter=VOWEL_CLASSES
)

print(f"âœ… Orden de clases detectado por Keras: {class_names}")
print(f"Total de clases: {len(class_names)}")


# ====================================================================
# --- 3. ARQUITECTURA CNN LIGERA PROPIA (Modificada para Grises) ---
# ====================================================================

print("\nðŸ—ï¸ Construyendo modelo CNN LIGERA (SeparableConv2D) con penalizaciÃ³n L2...")

strong_l2_reg = tf.keras.regularizers.l2(0.01)
model = models.Sequential([
    # ===================================================================
    # --- Â¡CAMBIO AQUÃ! ACEPTAR 1 CANAL DE ENTRADA ---
    # ===================================================================
    layers.SeparableConv2D(32, (3, 3), padding='same', 
                           input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 1)), # <-- CAMBIADO A 1 CANAL
    # ===================================================================
    
    layers.BatchNormalization(), 
    layers.LeakyReLU(alpha=0.1),
    layers.MaxPooling2D((2, 2)), 
    
    layers.SeparableConv2D(64, (3, 3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.2), 
    
    layers.SeparableConv2D(128, (3, 3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)), 
    layers.Dropout(0.3), 
    
    layers.SeparableConv2D(256, (3, 3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.GlobalAveragePooling2D(), 
    
    layers.Dropout(0.5), 
    layers.Dense(NUM_CLASSES, 
                 activation='softmax', 
                 dtype='float32',
                 kernel_regularizer=strong_l2_reg)
])

# CompilaciÃ³n (con el LR de la Fase 1)
optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE, beta_1=ADAM_BETA_1, beta_2=ADAM_BETA_2)
model.compile(
    optimizer=optimizer,
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()
total_params = model.count_params()
print(f"\nðŸ“Š ParÃ¡metros totales: {total_params:,}")
# El tamaÃ±o en MB serÃ¡ incluso menor ahora
print(f"âœ… Modelo ligero ({total_params * 4 / (1024**2):.2f} MB) y apto para cuantizaciÃ³n TFLite.")

# ====================================================================
# --- 4. CALLBACKS Y ENTRENAMIENTO (Con ajuste FASE 1) ---
# ====================================================================

# (Callback personalizado sin cambios)
class AccuracyThresholdCallback(tf.keras.callbacks.Callback):
    def __init__(self, threshold, filepath):
        super().__init__()
        self.threshold = threshold
        self.filepath = filepath
        self.best_acc_above_threshold = 0.0

    def on_epoch_end(self, epoch, logs=None):
        current_acc = logs.get('val_accuracy')
        if (current_acc is not None and 
            current_acc >= self.threshold and 
            current_acc > self.best_acc_above_threshold):
            
            self.best_acc_above_threshold = current_acc
            filename = self.filepath.format(epoch=epoch + 1, a=current_acc * 100)
            self.model.save(filename, overwrite=True)
            print(f"\nÃ‰poca {epoch + 1}: Â¡Guardado por Umbral! val_accuracy={current_acc:.4f} > {self.threshold*100}% en {filename}")


callbacks = [
    # ==================== SOLUCIÃ“N FASE 1: Callback de seguridad ====================
    tf.keras.callbacks.TerminateOnNaN(), # <-- AÃ‘ADIDO
    # ==============================================================================
    
    EarlyStopping(
        monitor='val_accuracy', 
        patience=20,
        restore_best_weights=True,
        verbose=1
    ),
    ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=12, 
        min_lr=1e-7,
        verbose=1
    ),
    ModelCheckpoint(
        'best_VOWEL_CustomCNN_TinyML_GRAYSCALE.keras', # Nombre de archivo actualizado
        monitor='val_accuracy',
        save_best_only=True,
        verbose=1
    ),
    AccuracyThresholdCallback(
        threshold=0.95, 
        filepath='VOWEL_GRAY_ACC95_E{epoch:02d}_ACC{a:.2f}.keras' # Nombre de archivo actualizado
    )
]

# --- 5. ENTRENAMIENTO ---
print("\nðŸš€ Iniciando entrenamiento (CON FONDOS ALEATORIOS Y SALIDA GRIS)...")

history = model.fit(
    train_dataset,
    epochs=EPOCHS,
    validation_data=validation_dataset,
    callbacks=callbacks,
    verbose=1
)

# --- 6. EVALUACIÃ“N FINAL Y GUARDADO ---
print("\nðŸ“ˆ Evaluando modelo final (VOCALES - GRISES)...")
# (Resto del cÃ³digo sin cambios)
loss, accuracy = model.evaluate(validation_dataset, verbose=0)

print(f"\n{'='*50}")
print(f"RESULTADOS FINALES (VOCALES - GRISES)")
print(f"{'='*50}")
print(f"PÃ©rdida (Loss):       {loss:.4f}")
print(f"Exactitud (Accuracy): {accuracy*100:.2f}%")
print(f"{'='*50}")

model_name = f'VOWEL_GRAY_96x96_CustomCNN_FINAL_ACC{accuracy*100:.2f}.keras'
model_path = os.path.join(os.getcwd(), model_name)
model.save(model_path)
print(f"\nðŸ’¾ Modelo guardado: {model_name}")

# --- 7. GUARDAR HISTORIAL DE ENTRENAMIENTO ---
history_data = {
    'accuracy': [float(x) for x in history.history['accuracy']],
    'val_accuracy': [float(x) for x in history.history['val_accuracy']],
    'loss': [float(x) for x in history.history['loss']],
    'val_loss': [float(x) for x in history.history['val_loss']]
}

with open('training_history_vowel_cnn_grayscale.json', 'w') as f:
    json.dump(history_data, f, indent=4)
print("ðŸ“Š Historial guardado en: training_history_vowel_cnn_grayscale.json")

print("\nâœ… Proceso completado exitosamente.")


# ====================================================================
# --- 8. (OPCIONAL) CÃ“DIGO DE DIAGNÃ“STICO (AJUSTADO PARA GRISES) ---
# ====================================================================

# NOTA: Como el 'train_dataset' ahora contiene imÃ¡genes en GRISES,
# este bloque de diagnÃ³stico debe cargar un lote de COLOR por separado
# para poder probar la lÃ³gica del Chroma Key (que SÃ usa color).

print("\nðŸ©º Iniciando DiagnÃ³stico de Chroma Key (Fondo Verde)...")

try:
    # Cargar un lote de IMÃGENES ORIGINALES (en color)
    color_ds = tf.keras.utils.image_dataset_from_directory(
        TRAIN_DIR,
        labels='inferred',
        label_mode='categorical',
        class_names=VOWEL_CLASSES,
        image_size=IMAGE_SIZE,
        interpolation='bilinear',
        batch_size=BATCH_SIZE, # Cargar un lote
        shuffle=True
    )

    # Combinar con un lote de fondos
    # (background_dataset ya fue creado y es infinito)
    diagnostic_ds = tf.data.Dataset.zip((color_ds, background_dataset.batch(BATCH_SIZE)))

    # Tomar el primer (y Ãºnico) lote
    for (images_color, labels), backgrounds_color in diagnostic_ds.take(1):
        
        # Tomar la primera imagen y fondo del lote
        img_orig = images_color[0] # Esta SÃ es a color
        bg_orig = backgrounds_color[0] 
        
        # --- Aplicar lÃ³gica de Chroma Key ---
        
        # Aplicar el chroma key
        img_blended_rgb = chroma_key_blend(img_orig, bg_orig)
        
        # Aplicar la conversiÃ³n a grises (para mostrar)
        img_blended_gray = tf.image.rgb_to_grayscale(img_blended_rgb)
        
        # --- Recrear la mÃ¡scara solo para visualizaciÃ³n ---
        img_hsv = tf.image.rgb_to_hsv(img_orig / 255.0)
        h, s, v = tf.split(img_hsv, 3, axis=-1)
        mask_h = tf.logical_and(h >= HSV_GREEN_MIN[0], h <= HSV_GREEN_MAX[0])
        mask_s = tf.logical_and(s >= HSV_GREEN_MIN[1], s <= HSV_GREEN_MAX[1])
        mask_v = tf.logical_and(v >= HSV_GREEN_MIN[2], v <= HSV_GREEN_MAX[2])
        green_mask_bool = tf.logical_and(mask_h, tf.logical_and(mask_s, mask_v))
        hand_mask_bool = tf.logical_not(green_mask_bool)
        hand_mask_float = tf.cast(hand_mask_bool, dtype=tf.float32)
        # --- Fin de recreaciÃ³n de mÃ¡scara ---
        
        # --- Mostrar resultados ---
        plt.figure(figsize=(15, 10))
        
        plt.subplot(2, 3, 1)
        plt.imshow(img_orig.numpy().astype("uint8"))
        plt.title("1. Original (Color)")
        plt.axis("off")
        
        plt.subplot(2, 3, 2)
        plt.imshow(bg_orig.numpy().astype("uint8"))
        plt.title("2. Fondo Aleatorio (Color)")
        plt.axis("off")
        
        plt.subplot(2, 3, 3)
        # .squeeze() elimina el canal '1' para que imshow sepa mostrarlo como gris
        plt.imshow(hand_mask_float.numpy().squeeze(), cmap='gray')
        plt.title("3. MÃ¡scara de la Mano (Blanca)")
        plt.axis("off")
        
        plt.subplot(2, 3, 4)
        plt.imshow(img_blended_rgb.numpy().astype("uint8"))
        plt.title("4. FusiÃ³n (en Color)")
        plt.axis("off")
        
        plt.subplot(2, 3, 5)
        plt.imshow(img_blended_gray.numpy().squeeze(), cmap='gray') 
        plt.title("5. Resultado Final (Grises)")
        plt.axis("off")
        
        plt.subplot(2, 3, 6)
        plt.axis("off") # Espacio vacÃ­o
        
        plt.suptitle("DiagnÃ³stico del Chroma Key (VersiÃ³n Grises)", fontsize=16)
        plt.show()

except Exception as e:
    print(f"âš ï¸ Error al generar diagnÃ³stico: {e}")
    print("AsegÃºrate de que las carpetas 'VOCALES/train' y 'backgrounds' existan.")